#!/usr/bin/env node
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __accessCheck = (obj, member, msg) => {
  if (!member.has(obj))
    throw TypeError("Cannot " + msg);
};
var __privateGet = (obj, member, getter) => {
  __accessCheck(obj, member, "read from private field");
  return getter ? getter.call(obj) : member.get(obj);
};
var __privateAdd = (obj, member, value) => {
  if (member.has(obj))
    throw TypeError("Cannot add the same private member more than once");
  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
};
var __privateMethod = (obj, member, method) => {
  __accessCheck(obj, member, "access private method");
  return method;
};

// src/cli.ts
var cli_exports = {};
__export(cli_exports, {
  l10nExportStrings: () => l10nExportStrings,
  l10nGeneratePseudo: () => l10nGeneratePseudo,
  l10nGenerateTranslationService: () => l10nGenerateTranslationService,
  l10nGenerateXlf: () => l10nGenerateXlf,
  l10nImportXlf: () => l10nImportXlf
});
module.exports = __toCommonJS(cli_exports);
var import_fs = require("fs");
var import_path = __toESM(require("path"));
var glob = __toESM(require("glob"));

// src/main.ts
var import_deepmerge_json = __toESM(require("deepmerge-json"));

// src/ast/analyzer.ts
var path = __toESM(require("path"));
var import_web_tree_sitter = __toESM(require("web-tree-sitter"));

// src/ast/queries.ts
var requireQuery = `(call_expression
	function: (identifier) @requireFunc (#eq? @requireFunc require)
	arguments: (arguments . (string (string_fragment) @requireArg (#match? @requireArg "^(vscode|@vscode/l10n)$")))
)`;
var righthandSideQuery = `[
	${requireQuery}
	(member_expression
		object: ${requireQuery}
		property: (property_identifier) @propertyIdentifier (#match? @propertyIdentifier "^(l10n|t)$")
	)
]`;
var variableDeclaratorRequireQuery = `(variable_declarator
	name: [
		((identifier) @variableName)
		(object_pattern [
			((shorthand_property_identifier_pattern) @propertyIdentifier (#match? @propertyIdentifier "^(l10n|t)$"))
			(pair_pattern
				key: (property_identifier) @propertyIdentifier (#match? @propertyIdentifier "^(l10n|t)$")
				value: (identifier) @propertyIdentifierAlias
			)
		])
	]
	value: ${righthandSideQuery}
)`;
var assignmentExpressionRequireQuery = `(assignment_expression
	left: (identifier) @variableName
	right: ${righthandSideQuery}
)`;
var importQuery = `(import_statement
	(import_clause [
		(namespace_import (identifier) @namespace)
		(named_imports (import_specifier
			name: (identifier) @namedImport (#match? @namedImport "^(l10n|t)$")
			alias: (identifier)? @namedImportAlias
		))
	])
	source: (string (string_fragment) @importArg (#match? @importArg "^(vscode|@vscode/l10n)$"))
)`;
var importOrRequireQuery = `${variableDeclaratorRequireQuery}
${assignmentExpressionRequireQuery}
${importQuery}`;
function getTQuery({ vscode = "vscode", l10n = "l10n", t = "t" }) {
  return `(call_expression
		(member_expression
			object: [
				((identifier) @l10n (#eq? @l10n ${l10n}))
				(member_expression
					object: (identifier) @vscode (#eq? @vscode ${vscode})
					property: (property_identifier) @l10n (#eq? @l10n ${l10n})
				)
			]
			property: (property_identifier) @t (#eq? @t ${t})
		)
		arguments: [
			(template_string (template_substitution)* @sub) @tagged_template
			(arguments . [(string) (template_string (template_substitution)? @message_template_arg)] @message)
			(arguments . (number) @message)
			(arguments . (object
				(pair
					key: (property_identifier) @message-prop (#eq? @message-prop message)
					value: [(string) (template_string (template_substitution)? @message_template_arg)] @message
				)
				(pair
					key: (property_identifier) @comment-prop (#eq? @comment-prop comment)
					value: [(string) (array) (template_string)] @comment
				)
			))
		]
	)`;
}

// src/ast/unescapeString.ts
var unescapeString = (text) => {
  for (let i = text.indexOf("\\"); i !== -1; i = text.indexOf("\\", i)) {
    if (text[i] !== "\\") {
      i++;
      continue;
    }
    let replace;
    let end = i + 2;
    const next = text[i + 1];
    switch (next) {
      case "n":
        replace = "\n";
        break;
      case "r":
        replace = "\r";
        break;
      case "t":
        replace = "	";
        break;
      case "x":
        end = i + 4;
        replace = String.fromCodePoint(parseInt(text.slice(i + 2, end), 16));
        break;
      case "u": {
        let int;
        if (text[i + 2] === "{") {
          end = text.indexOf("}") + 1;
          int = text.slice(i + 3, end - 1);
        } else {
          end = i + 6;
          int = text.slice(i + 2, end - 1);
        }
        replace = String.fromCodePoint(parseInt(int, 16));
        break;
      }
      default:
        replace = next;
        break;
    }
    text = text.slice(0, i) + replace + text.slice(end);
    i += replace.length;
  }
  return text;
};

// src/ast/analyzer.ts
try {
  const matches = /^v(\d+).\d+.\d+$/.exec(process.version);
  if (matches && matches[1]) {
    const majorVersion = matches[1];
    if (parseInt(majorVersion) >= 18) {
      delete WebAssembly.instantiateStreaming;
    }
  }
} catch {
}
var initParser = import_web_tree_sitter.default.init();
var _tsParser, _tsxParser, _tsGrammar, _tsxGrammar, _getCommentsFromMatch, getCommentsFromMatch_fn, _getTemplateValueFromTemplateRawValue, getTemplateValueFromTemplateRawValue_fn, _getStringFromMatch, getStringFromMatch_fn, _getUnquotedString, getUnquotedString_fn, _getImportDetails, getImportDetails_fn;
var _ScriptAnalyzer = class {
  constructor() {
    __privateAdd(this, _getCommentsFromMatch);
    __privateAdd(this, _getTemplateValueFromTemplateRawValue);
    __privateAdd(this, _getStringFromMatch);
    __privateAdd(this, _getUnquotedString);
    __privateAdd(this, _getImportDetails);
  }
  async analyze({ extension, contents }) {
    if (!contents.includes("l10n") || !contents.includes("vscode")) {
      return {};
    }
    let parser, grammar;
    switch (extension) {
      case ".jsx":
      case ".tsx":
        grammar = await __privateGet(_ScriptAnalyzer, _tsxGrammar);
        parser = await __privateGet(_ScriptAnalyzer, _tsxParser);
        break;
      case ".js":
      case ".ts":
        grammar = await __privateGet(_ScriptAnalyzer, _tsGrammar);
        parser = await __privateGet(_ScriptAnalyzer, _tsParser);
        break;
      default:
        throw new Error(`File format '${extension}' not supported.`);
    }
    const parsed = parser.parse(contents);
    const importQuery2 = grammar.query(importOrRequireQuery);
    const importMatches = importQuery2.matches(parsed.rootNode);
    const bundle = {};
    for (const importMatch of importMatches) {
      const importDetails = __privateMethod(this, _getImportDetails, getImportDetails_fn).call(this, importMatch);
      const query = grammar.query(getTQuery(importDetails));
      const matches = query.matches(parsed.rootNode);
      for (const match of matches) {
        const taggedTemplate = match.captures.find((c) => c.name === "tagged_template");
        let message;
        if (taggedTemplate) {
          const subs = match.captures.filter((c) => c.name === "sub");
          const start = taggedTemplate.node.startIndex;
          message = __privateMethod(this, _getTemplateValueFromTemplateRawValue, getTemplateValueFromTemplateRawValue_fn).call(this, taggedTemplate.node.text);
          for (let i = subs.length - 1; i >= 0; i--) {
            const sub = subs[i];
            message = message.slice(0, sub.node.startIndex - start) + `{${i}}` + message.slice(sub.node.endIndex - start);
          }
          message = __privateMethod(this, _getUnquotedString, getUnquotedString_fn).call(this, message);
        } else {
          message = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "message", true);
          const hasMessageTemplateArgs = match.captures.find((c) => c.name === "message_template_arg");
          if (hasMessageTemplateArgs) {
            throw new Error(`Message '${message}' contains args via template substitution, i.e. 'l10n.t(\`\${foo}\`)'. Please use double quotes and pass args, i.e. 'l10n.t(\`{0}\`, foo)'.`);
          }
        }
        const comment = __privateMethod(this, _getCommentsFromMatch, getCommentsFromMatch_fn).call(this, match);
        if (comment.length) {
          const key = `${message}/${comment.join("")}`;
          bundle[key] = { message, comment };
        } else {
          bundle[message] = message;
        }
      }
    }
    return bundle;
  }
};
var ScriptAnalyzer = _ScriptAnalyzer;
_tsParser = new WeakMap();
_tsxParser = new WeakMap();
_tsGrammar = new WeakMap();
_tsxGrammar = new WeakMap();
_getCommentsFromMatch = new WeakSet();
getCommentsFromMatch_fn = function(match) {
  const commentCapture = match.captures.find((c) => c.name === "comment");
  if (!commentCapture) {
    return [];
  }
  if (commentCapture.node.type === "string" || commentCapture.node.type === "template_string") {
    const text = commentCapture.node.text;
    return [__privateMethod(this, _getUnquotedString, getUnquotedString_fn).call(this, text)];
  }
  return commentCapture.node.children.filter((c) => c.type === "string" || c.type === "template_string").map((c) => __privateMethod(this, _getUnquotedString, getUnquotedString_fn).call(this, c.type === "string" ? c.text : __privateMethod(this, _getTemplateValueFromTemplateRawValue, getTemplateValueFromTemplateRawValue_fn).call(this, c.text)));
};
_getTemplateValueFromTemplateRawValue = new WeakSet();
getTemplateValueFromTemplateRawValue_fn = function(templateRawValue) {
  return templateRawValue.replace(/\r\n/g, "\n");
};
_getStringFromMatch = new WeakSet();
getStringFromMatch_fn = function(match, id, unescape) {
  const capture = match.captures.find((c) => c.name === id);
  if (!capture) {
    return void 0;
  }
  let text = capture.node.text;
  if (capture.node.type === "template_string") {
    text = __privateMethod(this, _getTemplateValueFromTemplateRawValue, getTemplateValueFromTemplateRawValue_fn).call(this, text);
  }
  if (!unescape) {
    return text;
  }
  return __privateMethod(this, _getUnquotedString, getUnquotedString_fn).call(this, text);
};
_getUnquotedString = new WeakSet();
getUnquotedString_fn = function(text) {
  const character = text[0];
  if (character !== "'" && character !== '"' && character !== "`") {
    return text;
  }
  return unescapeString(text.slice(1, -1));
};
_getImportDetails = new WeakSet();
getImportDetails_fn = function(match) {
  const importArg = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "importArg", false);
  if (importArg) {
    const namespace = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "namespace", false);
    if (namespace) {
      return importArg === "vscode" ? { vscode: namespace } : { l10n: namespace };
    }
    const namedImportAlias = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "namedImportAlias", false);
    return importArg === "vscode" ? { l10n: namedImportAlias } : { t: namedImportAlias };
  }
  const requireArg = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "requireArg", false);
  const propertyIdentifier = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "propertyIdentifier", false);
  const variableName = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "variableName", false);
  if (!propertyIdentifier) {
    return requireArg === "vscode" ? { vscode: variableName } : { l10n: variableName };
  }
  if (!variableName) {
    const propertyIdentifierAlias = __privateMethod(this, _getStringFromMatch, getStringFromMatch_fn).call(this, match, "propertyIdentifierAlias", false);
    return requireArg === "vscode" ? { l10n: propertyIdentifierAlias } : { t: propertyIdentifierAlias };
  }
  return requireArg === "vscode" ? { l10n: variableName } : { t: variableName };
};
__privateAdd(ScriptAnalyzer, _tsParser, (async () => {
  await initParser;
  const parser = new import_web_tree_sitter.default();
  parser.setLanguage(await __privateGet(_ScriptAnalyzer, _tsGrammar));
  return parser;
})());
__privateAdd(ScriptAnalyzer, _tsxParser, (async () => {
  await initParser;
  const parser = new import_web_tree_sitter.default();
  parser.setLanguage(await __privateGet(_ScriptAnalyzer, _tsxGrammar));
  return parser;
})());
__privateAdd(ScriptAnalyzer, _tsGrammar, (async () => {
  await initParser;
  return await import_web_tree_sitter.default.Language.load(
    path.resolve(__dirname, "tree-sitter-typescript.wasm")
  );
})());
__privateAdd(ScriptAnalyzer, _tsxGrammar, (async () => {
  await initParser;
  return await import_web_tree_sitter.default.Language.load(
    path.resolve(__dirname, "tree-sitter-tsx.wasm")
  );
})());

// src/logger.ts
var import_debug = __toESM(require("debug"));
import_debug.default.enable("WARNING" /* Warning */);
var logger = {
  verbose: (0, import_debug.default)("VERBOSE" /* Verbose */),
  debug: (0, import_debug.default)("DEBUG" /* Debug */),
  warning: (0, import_debug.default)("WARNING" /* Warning */),
  log: console.log,
  error: console.error,
  setLogLevel(level) {
    switch (level) {
      case "DEBUG" /* Debug */:
        import_debug.default.enable("DEBUG" /* Debug */);
        break;
      case "VERBOSE" /* Verbose */:
        import_debug.default.enable("VERBOSE" /* Verbose */);
        break;
      default:
        break;
    }
    import_debug.default.enable(level);
  }
};

// src/xlf/xlf.ts
var xml2js = __toESM(require("xml2js"));
var crypto = __toESM(require("crypto"));

// src/xlf/line.ts
var Line = class {
  constructor(indent = 0) {
    this.buffer = [];
    if (indent > 0) {
      this.buffer.push(new Array(indent + 1).join(" "));
    }
  }
  append(value) {
    this.buffer.push(value);
    return this;
  }
  toString() {
    return this.buffer.join("");
  }
};

// src/xlf/xlf.ts
var hashedIdSignal = "++CODE++";
var hashedIdLength = 72;
function getMessage(value) {
  return typeof value === "string" ? value : value.message;
}
function getComment(value) {
  return typeof value === "string" ? void 0 : value.comment;
}
function getValue(node) {
  if (!node) {
    return void 0;
  }
  if (typeof node === "string") {
    return node;
  }
  if (typeof node._ === "string") {
    return node._;
  }
  if (Array.isArray(node) && node.length === 1) {
    const item = node[0];
    if (typeof item === "string") {
      return item;
    }
    if (typeof item._ === "string") {
      return item._;
    }
    return node[0]._;
  }
  return void 0;
}
var XLF = class {
  constructor(options) {
    this.buffer = [];
    this.files = /* @__PURE__ */ new Map();
    this.sourceLanguage = options?.sourceLanguage ?? "en";
  }
  toString() {
    this.appendHeader();
    const filesSorted = [...this.files].sort((a, b) => a[0] > b[0] ? 1 : -1);
    for (const [file, items] of filesSorted) {
      this.appendNewLine(`<file original="${file}" source-language="${this.sourceLanguage}" datatype="plaintext"><body>`, 2);
      const itemsSorted = items.sort((a, b) => a.message > b.message ? 1 : -1);
      for (const item of itemsSorted) {
        this.addStringItem(item);
      }
      this.appendNewLine("</body></file>", 2);
    }
    this.appendFooter();
    return this.buffer.join("\r\n");
  }
  addFile(key, bundle) {
    if (Object.keys(bundle).length === 0) {
      return;
    }
    this.files.set(key, []);
    const existingKeys = /* @__PURE__ */ new Set();
    for (const id in bundle) {
      if (existingKeys.has(id)) {
        continue;
      }
      existingKeys.add(id);
      const message = encodeEntities(getMessage(bundle[id]));
      const comment = getComment(bundle[id])?.map((c) => encodeEntities(c)).join(`\r
`);
      this.files.get(key).push({ id: encodeEntities(id), message, comment });
    }
  }
  addStringItem(item) {
    if (!item.id || !item.message) {
      throw new Error("No item ID or value specified.");
    }
    const id = item.id.startsWith(item.message) ? hashedIdSignal + crypto.createHash("sha256").update(item.id, "binary").digest("hex") : item.id;
    this.appendNewLine(`<trans-unit id="${encodeEntities(id)}">`, 4);
    this.appendNewLine(`<source xml:lang="${this.sourceLanguage}">${item.message}</source>`, 6);
    if (item.comment) {
      this.appendNewLine(`<note>${item.comment}</note>`, 6);
    }
    this.appendNewLine("</trans-unit>", 4);
  }
  appendHeader() {
    this.appendNewLine('<?xml version="1.0" encoding="utf-8"?>', 0);
    this.appendNewLine('<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2">', 0);
  }
  appendFooter() {
    this.appendNewLine("</xliff>", 0);
  }
  appendNewLine(content, indent) {
    const line = new Line(indent);
    line.append(content);
    this.buffer.push(line.toString());
  }
  static async parse(xlfString) {
    const parser = new xml2js.Parser();
    const files = [];
    const result = await parser.parseStringPromise(xlfString);
    const fileNodes = result["xliff"]["file"];
    if (!fileNodes) {
      throw new Error('XLIFF file does not contain "xliff" or "file" node(s) required for parsing.');
    }
    fileNodes.forEach((file) => {
      const name = file.$.original;
      if (!name) {
        throw new Error("XLIFF file node does not contain original attribute to determine the original location of the resource file.");
      }
      const language = file.$["target-language"].toLowerCase();
      if (!language) {
        throw new Error("XLIFF file node does not contain target-language attribute to determine translated language.");
      }
      const messagesMap = /* @__PURE__ */ new Map();
      const transUnits = file.body[0]["trans-unit"];
      if (transUnits) {
        transUnits.forEach((unit) => {
          if (!unit.target) {
            return;
          }
          const target = getValue(unit.target);
          if (!target) {
            throw new Error("XLIFF file does not contain full localization data. target node in one of the trans-unit nodes is not present.");
          }
          let key;
          if (!unit.$.id.startsWith(hashedIdSignal) || unit.$.id.length !== hashedIdLength) {
            key = unit.$.id;
          } else {
            const source = getValue(unit.source);
            if (!source) {
              throw new Error("XLIFF file does not contain full localization data. source node in one of the trans-unit nodes is not present.");
            }
            const note = getValue(unit.note);
            key = source;
            if (note) {
              key += "/" + note.replace(/\r?\n/g, "");
            }
          }
          messagesMap.set(key, decodeEntities(target));
        });
        const messages = {};
        for (const key of [...messagesMap.keys()].sort()) {
          messages[key] = messagesMap.get(key);
        }
        files.push({ messages, name, language });
      }
    });
    return files.sort((a, b) => a.name.localeCompare(b.name));
  }
};
function encodeEntities(value) {
  const result = [];
  for (let i = 0; i < value.length; i++) {
    const ch = value[i];
    switch (ch) {
      case '"':
        result.push("&quot;");
        break;
      case "'":
        result.push("&apos;");
        break;
      case "<":
        result.push("&lt;");
        break;
      case ">":
        result.push("&gt;");
        break;
      case "&":
        result.push("&amp;");
        break;
      case "\n":
        result.push("&#10;");
        break;
      case "\r":
        result.push("&#13;");
        break;
      default:
        result.push(ch);
    }
  }
  return result.join("");
}
function decodeEntities(value) {
  return value.replace(/&quot;/g, '"').replace(/&apos;/g, "'").replace(/&lt;/g, "<").replace(/&gt;/g, ">").replace(/&#10;/g, "\n").replace(/&#13;/g, "\r").replace(/&amp;/g, "&");
}

// src/translators/azure.ts
var import_markdown_it = __toESM(require("markdown-it"));
var import_ai_translation_text = __toESM(require("@azure-rest/ai-translation-text"));
var import_node_html_markdown = require("node-html-markdown");
var MAX_SIZE_OF_ARRAY_ELEMENT = 5e4;
var MAX_NUMBER_OF_ARRAY_ELEMENTS = 1e3;
var MAX_REQUEST_SIZE = 5e4;
var client;
function translate(body, languages, config) {
  client ?? (client = (0, import_ai_translation_text.default)("https://api.cognitive.microsofttranslator.com/", { key: config.azureTranslatorKey, region: config.azureTranslatorRegion }));
  const to = languages.join(",");
  return client.path("/translate").post({
    body,
    queryParameters: {
      to,
      from: "en",
      textType: "html"
    }
  });
}
async function batchTranslate(body, languages, config) {
  const promises = [];
  let partialBody = [];
  let currentCharacterCount = 0;
  for (const item of body) {
    if (item.text.length > MAX_SIZE_OF_ARRAY_ELEMENT) {
      throw new Error(`Failed to translate. Item is too large: ${item.text}`);
    }
    const requestAddition = item.text.length * languages.length;
    if (currentCharacterCount + requestAddition > MAX_REQUEST_SIZE || partialBody.length === MAX_NUMBER_OF_ARRAY_ELEMENTS) {
      promises.push(translate(partialBody, languages, config));
      partialBody = [];
      currentCharacterCount = 0;
    }
    partialBody.push(item);
    currentCharacterCount += requestAddition;
  }
  if (partialBody.length > 0) {
    promises.push(translate(partialBody, languages, config));
  }
  const responses = await Promise.allSettled(promises);
  const outputs = [];
  for (const response of responses) {
    if (response.status === "fulfilled") {
      switch (response.value.status) {
        case "200":
          outputs.push(...response.value.body);
          break;
        default: {
          const error = response.value.body;
          throw new Error(`Failed to translate: ${error.error.message}`);
        }
      }
    } else {
      throw response.reason;
    }
  }
  return outputs;
}
function handleSuccess(outputs, keys) {
  const files = [];
  for (let i = 0; i < outputs.length; i++) {
    const output = outputs[i];
    output?.translations.forEach((translation, languageIndex) => {
      files[languageIndex] ?? (files[languageIndex] = {});
      files[languageIndex][keys[i]] = import_node_html_markdown.NodeHtmlMarkdown.translate(translation.text);
    });
  }
  return files;
}
var md;
async function azureTranslatorTranslate(dataToLocalize, languages, config) {
  md ?? (md = (0, import_markdown_it.default)());
  client ?? (client = (0, import_ai_translation_text.default)("https://api.cognitive.microsofttranslator.com/", { key: config.azureTranslatorKey, region: config.azureTranslatorRegion }));
  const body = [];
  const keys = Object.keys(dataToLocalize);
  for (const key of keys) {
    const value = dataToLocalize[key];
    const message = typeof value === "string" ? value : value.message;
    const html = md.render(message);
    body.push({ text: html });
  }
  const result = await batchTranslate(body, languages, config);
  return handleSuccess(result, keys);
}

// src/translators/pseudo.ts
var import_pseudo_localization = require("pseudo-localization");
function pseudoLocalizedTranslate(dataToLocalize) {
  const contents = JSON.parse(JSON.stringify(dataToLocalize));
  for (const key of Object.keys(contents)) {
    const value = contents[key];
    const message = typeof value === "string" ? value : value.message;
    let index = 0;
    let localized = "";
    for (const match of message.matchAll(/(?:\(command:\S+)|(?:\$\([A-Za-z-~]+\))|(?:\{\S+\})/g)) {
      const section = (0, import_pseudo_localization.localize)(message.substring(index, match.index));
      localized += section + match[0];
      index = match.index + match[0].length;
    }
    contents[key] = index === 0 ? (0, import_pseudo_localization.localize)(message) : localized + (0, import_pseudo_localization.localize)(message.substring(index));
  }
  return contents;
}

// src/main.ts
var analyzer = new ScriptAnalyzer();
async function getL10nJson(fileContents) {
  logger.debug(`Analyzing ${fileContents.length} script files...`);
  const seenKeys = /* @__PURE__ */ new Set();
  const bundles = [];
  for (const contents of fileContents) {
    const result = await analyzer.analyze(contents);
    bundles.push(result);
    for (const [key, value] of Object.entries(result)) {
      if (seenKeys.has(key)) {
        logger.verbose(`The string '${key}' without comments has been seen multiple times.`);
      } else if (typeof value === "string" || !value.comment.length) {
        seenKeys.add(key);
      }
    }
  }
  logger.debug("Analyzed script files.");
  const mergedJson = import_deepmerge_json.default.multi({}, ...bundles);
  return mergedJson;
}
function getL10nXlf(l10nFileContents, options) {
  logger.debug(`Analyzing ${l10nFileContents.size} L10N files...`);
  const xlf = new XLF(options);
  for (const [name, l10nBundle] of l10nFileContents) {
    logger.debug(`Adding file ${name}...`);
    xlf.addFile(name, l10nBundle);
    logger.debug(`Added file ${name}.`);
  }
  logger.debug("Analyzed L10N files.");
  return xlf.toString();
}
async function getL10nFilesFromXlf(xlfContents) {
  logger.debug("Parsing XLF content...");
  const details = await XLF.parse(xlfContents);
  logger.debug(`Parsed XLF contents into ${details.length}.`);
  details.forEach((detail) => {
    logger.debug(`Found ${detail.language} file with ${Object.keys(detail.messages).length} messages called '${detail.name}'.`);
    switch (detail.language) {
      case "zh-hans":
        detail.language = "zh-cn";
        logger.debug(`Changed 'zh-hans' to 'zh-cn' for file: ${detail.name}.`);
        break;
      case "zh-hant":
        detail.language = "zh-tw";
        logger.debug(`Changed 'zh-hant' to 'zh-tw' for file: ${detail.name}.`);
        break;
      default:
        break;
    }
  });
  return details;
}
function getL10nPseudoLocalized(dataToLocalize) {
  logger.debug("Localizing data using pseudo-localization...");
  const result = pseudoLocalizedTranslate(dataToLocalize);
  logger.debug(`Pseudo-localized ${Object.keys(result).length} strings.`);
  return result;
}
async function getL10nAzureLocalized(dataToLocalize, languages, config) {
  logger.debug("Localizing data using Azure...");
  const result = await azureTranslatorTranslate(dataToLocalize, languages, config);
  if (result.length) {
    logger.debug(`Localized ${Object.keys(result[0]).length * languages.length} strings.`);
  } else {
    logger.debug("No strings localized.");
  }
  return result;
}

// src/cli.ts
var import_yargs = __toESM(require("yargs"));
var import_helpers = require("yargs/helpers");
var GLOB_DEFAULTS = {
  nodir: true,
  absolute: true,
  windowsPathsNoEscape: true
};
(0, import_yargs.default)((0, import_helpers.hideBin)(process.argv)).scriptName("vscode-l10n-dev").usage("$0 <cmd> [args]").option("verbose", {
  alias: "v",
  boolean: true,
  describe: "Enable verbose logging"
}).option("debug", {
  alias: "d",
  boolean: true,
  describe: "Enable debug logging"
}).middleware(function(argv) {
  if (argv.debug) {
    logger.setLogLevel("DEBUG" /* Debug */);
  } else if (argv.verbose) {
    logger.setLogLevel("VERBOSE" /* Verbose */);
  }
}).command(
  "export [args] <path..>",
  "Export strings from source files. Supports glob patterns.",
  (yargs2) => {
    yargs2.positional("path", {
      demandOption: true,
      type: "string",
      array: true,
      describe: "TypeScript files to extract strings from. Supports folders and glob patterns."
    });
    yargs2.option("outDir", {
      alias: "o",
      string: true,
      describe: "Output directory"
    });
  },
  async function(argv) {
    await l10nExportStrings(argv.path, argv.outDir);
  }
).command(
  "generate-xlf [args] <path..>",
  "Generate an XLF file from a collection of `*.l10n.json` or `package.nls.json` files. Supports glob patterns.",
  (yargs2) => {
    yargs2.positional("path", {
      demandOption: true,
      type: "string",
      array: true,
      normalize: true,
      describe: "L10N JSON files to generate an XLF from. Supports folders and glob patterns."
    });
    yargs2.option("outFile", {
      demandOption: true,
      string: true,
      describe: "Output file",
      alias: "o"
    });
    yargs2.option("language", {
      alias: "l",
      string: true,
      default: "en",
      describe: "The source language that will be written to the XLF file."
    });
  },
  function(argv) {
    l10nGenerateXlf(argv.path, argv.language, argv.outFile);
  }
).command(
  "import-xlf [args] <path..>",
  "Import an XLF file into a JSON l10n file",
  (yargs2) => {
    yargs2.positional("path", {
      demandOption: true,
      type: "string",
      array: true,
      normalize: true,
      describe: "XLF files to turn into `*.l10n.<language>.json` files. Supports folders and glob patterns."
    });
    yargs2.option("outDir", {
      alias: "o",
      string: true,
      default: ".",
      describe: "Output directory that will contain the l10n.<language>.json files"
    });
  },
  async function(argv) {
    await l10nImportXlf(argv.path, argv.outDir);
  }
).command(
  "generate-pseudo [args] <path..>",
  "Generate Pseudo language files for `*.l10n.json` or `package.nls.json` files. This is useful for testing localization with the Pseudo Language Language Pack in VS Code.",
  (yargs2) => {
    yargs2.positional("path", {
      demandOption: true,
      type: "string",
      array: true,
      normalize: true,
      describe: "L10N JSON files to generate an XLF from. Supports folders and glob patterns."
    });
    yargs2.option("language", {
      alias: "l",
      string: true,
      default: "qps-ploc",
      describe: "The Pseudo language identifier that will be used."
    });
  },
  function(argv) {
    l10nGeneratePseudo(argv.path, argv.language);
  }
).command(
  "generate-azure [args] <path..>",
  "(Experimental) Generate language files for `*.l10n.json` or `package.nls.json` files. You must create an Azure Translator instance, get the key and region, and set the AZURE_TRANSLATOR_KEY and AZURE_TRANSLATOR_REGION environment variables to these values.",
  (yargs2) => {
    yargs2.positional("path", {
      demandOption: true,
      type: "string",
      array: true,
      normalize: true,
      describe: "L10N JSON files to generate an XLF from. Supports folders and glob patterns."
    });
    yargs2.option("languages", {
      alias: "l",
      type: "string",
      array: true,
      default: ["fr", "it", "de", "es", "ru", "zh-cn", "zh-tw", "ja", "ko", "cs", "pt-br", "tr", "pl"],
      describe: "The Pseudo language identifier that will be used."
    });
    yargs2.env("AZURE_TRANSLATOR");
  },
  async function(argv) {
    if (!argv.key) {
      throw new Error("AZURE_TRANSLATOR_KEY environment variable is not defined.");
    }
    if (!argv.region) {
      throw new Error("AZURE_TRANSLATOR_REGION environment variable is not defined.");
    }
    await l10nGenerateTranslationService(
      argv.path,
      argv.languages,
      argv.key,
      argv.region
    );
  }
).help().argv;
async function l10nExportStrings(paths, outDir) {
  logger.log("Searching for TypeScript/JavaScript files...");
  const matches = glob.sync(
    paths.map((p) => /\.(ts|tsx|js|jsx)$/.test(p) ? p : import_path.default.posix.join(p, "{,**}", "*.{ts,tsx,js,jsx}")),
    GLOB_DEFAULTS
  );
  const tsFileContents = matches.map((m) => ({
    extension: import_path.default.extname(m),
    contents: (0, import_fs.readFileSync)(import_path.default.resolve(m), "utf8")
  }));
  if (!tsFileContents.length) {
    logger.log("No TypeScript files found.");
    return;
  }
  logger.log(`Found ${tsFileContents.length} TypeScript files. Extracting strings...`);
  const jsonResult = await getL10nJson(tsFileContents);
  const stringsFound = Object.keys(jsonResult).length;
  if (!stringsFound) {
    logger.log("No strings found. Skipping writing to a bundle.l10n.json.");
    return;
  }
  logger.log(`Extracted ${stringsFound} strings...`);
  let packageJSON;
  try {
    packageJSON = JSON.parse((0, import_fs.readFileSync)("package.json").toString("utf-8"));
  } catch (err) {
  }
  if (packageJSON) {
    if (outDir) {
      if (!packageJSON.l10n || import_path.default.resolve(packageJSON.l10n) !== import_path.default.resolve(outDir)) {
        console.warn("The l10n property in the package.json does not match the outDir specified. For an extension to work correctly, l10n must be set to the location of the bundle files.");
      }
    } else {
      outDir = packageJSON.l10n ?? ".";
    }
  } else {
    if (!outDir) {
      console.debug("No package.json found in directory and no outDir specified. Using the current directory.");
      return;
    }
    outDir = outDir ?? ".";
  }
  const resolvedOutFile = import_path.default.resolve(import_path.default.join(outDir, "bundle.l10n.json"));
  console.info(`Writing exported strings to: ${resolvedOutFile}`);
  (0, import_fs.mkdirSync)(import_path.default.resolve(outDir), { recursive: true });
  (0, import_fs.writeFileSync)(resolvedOutFile, JSON.stringify(jsonResult, void 0, 2));
}
function l10nGenerateXlf(paths, language, outFile) {
  logger.log("Searching for L10N JSON files...");
  const matches = glob.sync(
    paths.map((p) => /(\.l10n\.json|package\.nls\.json)$/.test(p) ? p : import_path.default.posix.join(p, `{,!(node_modules)/**}`, "{*.l10n.json,package.nls.json}")),
    GLOB_DEFAULTS
  );
  const l10nFileContents = /* @__PURE__ */ new Map();
  for (const match of matches) {
    if (match.endsWith(".l10n.json")) {
      const name = import_path.default.basename(match).split(".l10n.json")[0] ?? "";
      l10nFileContents.set(name, JSON.parse((0, import_fs.readFileSync)(import_path.default.resolve(match), "utf8")));
    } else if (match.endsWith("package.nls.json")) {
      l10nFileContents.set("package", JSON.parse((0, import_fs.readFileSync)(import_path.default.resolve(match), "utf8")));
    }
  }
  if (!l10nFileContents.size) {
    logger.log("No L10N JSON files found so skipping generating XLF.");
    return;
  }
  logger.log(`Found ${l10nFileContents.size} L10N JSON files. Generating XLF...`);
  const result = getL10nXlf(l10nFileContents, { sourceLanguage: language });
  (0, import_fs.writeFileSync)(import_path.default.resolve(outFile), result);
  logger.log(`Wrote XLF file to: ${outFile}`);
}
async function l10nImportXlf(paths, outDir) {
  logger.log("Searching for XLF files...");
  const matches = glob.sync(
    paths.map((p) => /\.xlf$/.test(p) ? p : import_path.default.posix.join(p, `{,!(node_modules)/**}`, "*.xlf")),
    GLOB_DEFAULTS
  );
  const xlfFiles = matches.map((m) => (0, import_fs.readFileSync)(import_path.default.resolve(m), "utf8"));
  if (!xlfFiles.length) {
    logger.log("No XLF files found.");
    return;
  }
  logger.log(`Found ${xlfFiles.length} XLF files. Generating localized L10N JSON files...`);
  let count = 0;
  if (xlfFiles.length) {
    (0, import_fs.mkdirSync)(import_path.default.resolve(outDir), { recursive: true });
  }
  for (const xlfContents of xlfFiles) {
    const details = await getL10nFilesFromXlf(xlfContents);
    count += details.length;
    for (const detail of details) {
      const type = detail.name === "package" ? "nls" : "l10n";
      (0, import_fs.writeFileSync)(
        import_path.default.resolve(import_path.default.join(outDir, `${detail.name}.${type}.${detail.language}.json`)),
        JSON.stringify(detail.messages, void 0, 2)
      );
    }
  }
  logger.log(`Wrote ${count} localized L10N JSON files to: ${outDir}`);
}
function l10nGeneratePseudo(paths, language) {
  logger.log("Searching for L10N JSON files...");
  const matches = glob.sync(
    paths.map((p) => /(\.l10n\.json|package\.nls\.json)$/.test(p) ? p : import_path.default.posix.join(p, `{,!(node_modules)/**}`, "{*.l10n.json,package.nls.json}")),
    GLOB_DEFAULTS
  );
  for (const match of matches) {
    const contents = getL10nPseudoLocalized(JSON.parse((0, import_fs.readFileSync)(import_path.default.resolve(match), "utf8")));
    if (match.endsWith(".l10n.json")) {
      const name = import_path.default.basename(match).split(".l10n.json")[0] ?? "";
      (0, import_fs.writeFileSync)(
        import_path.default.resolve(import_path.default.join(import_path.default.dirname(match), `${name}.l10n.${language}.json`)),
        JSON.stringify(contents, void 0, 2)
      );
    } else if (import_path.default.basename(match) === "package.nls.json") {
      (0, import_fs.writeFileSync)(
        import_path.default.resolve(import_path.default.join(import_path.default.dirname(match), `package.nls.${language}.json`)),
        JSON.stringify(contents, void 0, 2)
      );
    }
  }
  if (!matches.length) {
    logger.log("No L10N JSON files.");
    return;
  }
  logger.log(`Wrote ${matches.length} L10N JSON files.`);
}
async function l10nGenerateTranslationService(paths, languages, key, region) {
  logger.log("Searching for L10N JSON files...");
  const matches = glob.sync(
    paths.map((p) => /(\.l10n\.json|package\.nls\.json)$/.test(p) ? p : import_path.default.posix.join(p, `{,!(node_modules)/**}`, "{*.l10n.json,package.nls.json}")),
    GLOB_DEFAULTS
  );
  for (const match of matches) {
    const contents = await getL10nAzureLocalized(
      JSON.parse((0, import_fs.readFileSync)(import_path.default.resolve(match), "utf8")),
      languages,
      { azureTranslatorKey: key, azureTranslatorRegion: region }
    );
    for (let i = 0; i < languages.length; i++) {
      const language = languages[i];
      if (match.endsWith(".l10n.json")) {
        const name = import_path.default.basename(match).split(".l10n.json")[0] ?? "";
        (0, import_fs.writeFileSync)(
          import_path.default.resolve(import_path.default.join(import_path.default.dirname(match), `${name}.l10n.${language}.json`)),
          JSON.stringify(contents[i], void 0, 2)
        );
      } else if (import_path.default.basename(match) === "package.nls.json") {
        (0, import_fs.writeFileSync)(
          import_path.default.resolve(import_path.default.join(import_path.default.dirname(match), `package.nls.${language}.json`)),
          JSON.stringify(contents[i], void 0, 2)
        );
      }
    }
  }
  if (!matches.length) {
    logger.log("No L10N JSON files.");
    return;
  }
  logger.log(`Wrote ${matches.length * languages.length} L10N JSON files.`);
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  l10nExportStrings,
  l10nGeneratePseudo,
  l10nGenerateTranslationService,
  l10nGenerateXlf,
  l10nImportXlf
});
